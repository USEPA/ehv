{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d919b0-b8ad-4d3c-b785-06edfbf22135",
   "metadata": {},
   "source": [
    "# EHV Term to Graphite\n",
    "\n",
    "Generate exports for a curated list of possible canddiate terms to be added to the EHV, using extractions from HAWC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b463342-fc86-443b-a004-94bc1191ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cf1961c-f5d6-4235-a256-40a1de7c75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DJANGO_ALLOW_ASYNC_UNSAFE=true\n",
      "env: DJANGO_SETTINGS_MODULE=hawc.main.settings.dev\n"
     ]
    }
   ],
   "source": [
    "%env DJANGO_ALLOW_ASYNC_UNSAFE true\n",
    "%env DJANGO_SETTINGS_MODULE hawc.main.settings.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38100ee-c0e8-4c14-adeb-f2f8b6a98e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import django\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea39398-2de3-4efe-801e-95ec6d27b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from django.db.models import Q\n",
    "\n",
    "from hawc.apps.animal.models import Endpoint\n",
    "\n",
    "today = datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c44205-0bb7-42b3-8075-c8e3b7a64a94",
   "metadata": {},
   "source": [
    "### SR Automation Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0855337e-8127-4965-b556-85f9fd231880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from rapidfuzz import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8a6649-74a3-4527-ad6e-1e6843c79fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4bd55-61ea-4ad1-afc4-03e576f57246",
   "metadata": {},
   "source": [
    "## Get all endpoints where EHV is unused\n",
    "### Requires a local copy of a HAWC deployment's database\n",
    "\n",
    "Preserve endpoint relations. This is designed to give a little more metadata for assistance in mapping relations, but is not as useful for ranking or prioritization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4f65e97-2342-45b4-9bca-7d50e928cd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint_id</th>\n",
       "      <th>study_citation</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>system</th>\n",
       "      <th>organ</th>\n",
       "      <th>effect</th>\n",
       "      <th>effect_subtype</th>\n",
       "      <th>name</th>\n",
       "      <th>system_term_id</th>\n",
       "      <th>organ_term_id</th>\n",
       "      <th>effect_term_id</th>\n",
       "      <th>effect_subtype_term_id</th>\n",
       "      <th>name_term_id</th>\n",
       "      <th>created</th>\n",
       "      <th>last_updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100580551</td>\n",
       "      <td>Witchey SK et al. 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Nervous</td>\n",
       "      <td>Brain Weight, Cholinesterase</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Nervous Effects</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2024-10-01 04:41:27.211868+00:00</td>\n",
       "      <td>2024-10-01 04:41:27.211880+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100580543</td>\n",
       "      <td>Witchey SK et al. 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Developmental</td>\n",
       "      <td>Offspring Body Weight, Vaginal Opening,</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Developmental Effects</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2024-10-01 03:48:10.954082+00:00</td>\n",
       "      <td>2024-10-01 04:37:04.520624+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100580542</td>\n",
       "      <td>Witchey SK et al. 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Developmental</td>\n",
       "      <td>Offspring Body Weight, Balanopreputial Seperat...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Developmental Effects</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2024-10-01 03:43:08.505855+00:00</td>\n",
       "      <td>2024-10-01 04:36:31.503252+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100580544</td>\n",
       "      <td>Witchey SK et al. 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Hepatic</td>\n",
       "      <td>Liver Weight, Cholinesterase</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hepatic Effects</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2024-10-01 04:01:31.441228+00:00</td>\n",
       "      <td>2024-10-01 04:34:59.110171+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100580550</td>\n",
       "      <td>Witchey SK et al. 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Hepatic</td>\n",
       "      <td>Cholinesterase</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hepatic Effects</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2024-10-01 04:33:14.118446+00:00</td>\n",
       "      <td>2024-10-01 04:34:13.466542+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   endpoint_id          study_citation  vocabulary         system  \\\n",
       "0    100580551  Witchey SK et al. 2023        True        Nervous   \n",
       "1    100580543  Witchey SK et al. 2023        True  Developmental   \n",
       "2    100580542  Witchey SK et al. 2023        True  Developmental   \n",
       "3    100580544  Witchey SK et al. 2023        True        Hepatic   \n",
       "4    100580550  Witchey SK et al. 2023        True        Hepatic   \n",
       "\n",
       "                                               organ effect effect_subtype  \\\n",
       "0                       Brain Weight, Cholinesterase                         \n",
       "1            Offspring Body Weight, Vaginal Opening,                         \n",
       "2  Offspring Body Weight, Balanopreputial Seperat...                         \n",
       "3                       Liver Weight, Cholinesterase                         \n",
       "4                                     Cholinesterase                         \n",
       "\n",
       "                    name system_term_id organ_term_id effect_term_id  \\\n",
       "0        Nervous Effects           NULL          NULL           NULL   \n",
       "1  Developmental Effects           NULL          NULL           NULL   \n",
       "2  Developmental Effects           NULL          NULL           NULL   \n",
       "3        Hepatic Effects           NULL          NULL           NULL   \n",
       "4        Hepatic Effects           NULL          NULL           NULL   \n",
       "\n",
       "  effect_subtype_term_id name_term_id                          created  \\\n",
       "0                   NULL         NULL 2024-10-01 04:41:27.211868+00:00   \n",
       "1                   NULL         NULL 2024-10-01 03:48:10.954082+00:00   \n",
       "2                   NULL         NULL 2024-10-01 03:43:08.505855+00:00   \n",
       "3                   NULL         NULL 2024-10-01 04:01:31.441228+00:00   \n",
       "4                   NULL         NULL 2024-10-01 04:33:14.118446+00:00   \n",
       "\n",
       "                      last_updated  \n",
       "0 2024-10-01 04:41:27.211880+00:00  \n",
       "1 2024-10-01 04:37:04.520624+00:00  \n",
       "2 2024-10-01 04:36:31.503252+00:00  \n",
       "3 2024-10-01 04:34:59.110171+00:00  \n",
       "4 2024-10-01 04:34:13.466542+00:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_df(qs):\n",
    "    data=qs.values_list(\n",
    "        'id', 'animal_group__experiment__study__short_citation', 'assessment__vocabulary', \n",
    "        'system', 'organ', 'effect', 'effect_subtype', 'name',\n",
    "        'system_term_id', 'organ_term_id', 'effect_term_id', 'effect_subtype_term_id', 'name_term_id',\n",
    "        'created', 'last_updated'\n",
    "    )\n",
    "    df =  pd.DataFrame(\n",
    "        data=data, \n",
    "        columns=[\n",
    "            'endpoint_id', 'study_citation', 'vocabulary', \n",
    "            'system', 'organ', 'effect', 'effect_subtype', 'name',\n",
    "            'system_term_id', 'organ_term_id', 'effect_term_id', 'effect_subtype_term_id', 'name_term_id',\n",
    "            'created', 'last_updated'\n",
    "            \n",
    "        ]\n",
    "    )\n",
    "    df.loc[:, \"vocabulary\"] = df.vocabulary.fillna(0)\n",
    "    df.loc[:, \"vocabulary\"] = df.vocabulary.map({0: False, 1: True})\n",
    "    df[['system_term_id', 'organ_term_id', 'effect_term_id', 'effect_subtype_term_id', 'name_term_id']] = \\\n",
    "        df[['system_term_id', 'organ_term_id', 'effect_term_id', 'effect_subtype_term_id', 'name_term_id']].fillna(\"NULL\")\n",
    "    return df\n",
    "\n",
    "\n",
    "q_filters = (\n",
    "    Q(system_term_id__isnull=True) | \n",
    "    Q(organ_term_id__isnull=True) | \n",
    "    Q(effect_term_id__isnull=True) | \n",
    "    Q(effect_subtype_term_id__isnull=True) | \n",
    "    Q(name_term_id__isnull=True)\n",
    ")\n",
    "\n",
    "df1 = to_df(Endpoint.objects.filter(q_filters).order_by('-last_updated').select_related('assessment', 'animal_group__experiment__study'))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504bae27-7e12-49a6-ba64-4312feb14726",
   "metadata": {},
   "source": [
    "## Get most frequently used missing terms\n",
    "\n",
    "Filter for cases where EHV is enabled, values count where term is repeated and missing. Filter to only include cases where the same term was used more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a3f0a3-9f2c-40e6-a686-efed5bb75102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.db.models import Count, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5feb75b-3db4-49ed-b524-e22b765ffcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2381\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>term</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>system</td>\n",
       "      <td>Developmental</td>\n",
       "      <td>3456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>organ</td>\n",
       "      <td>Whole Body</td>\n",
       "      <td>3351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>effect</td>\n",
       "      <td>Pregnancy Outcome</td>\n",
       "      <td>2931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>effect_subtype</td>\n",
       "      <td>Clinical Observation</td>\n",
       "      <td>2089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>effect_subtype</td>\n",
       "      <td>Histopathology</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>system</td>\n",
       "      <td>Nervous</td>\n",
       "      <td>1687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>effect</td>\n",
       "      <td>Behavioral Function</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effect_subtype</td>\n",
       "      <td>Offspring Growth</td>\n",
       "      <td>1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>organ</td>\n",
       "      <td>CNS</td>\n",
       "      <td>1466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effect</td>\n",
       "      <td>Histopathology</td>\n",
       "      <td>1360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             type                  term  count\n",
       "0          system         Developmental   3456\n",
       "0           organ            Whole Body   3351\n",
       "0          effect     Pregnancy Outcome   2931\n",
       "0  effect_subtype  Clinical Observation   2089\n",
       "1  effect_subtype        Histopathology   1949\n",
       "1          system               Nervous   1687\n",
       "1          effect   Behavioral Function   1610\n",
       "2  effect_subtype      Offspring Growth   1582\n",
       "1           organ                   CNS   1466\n",
       "2          effect        Histopathology   1360"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs1 = (\n",
    "    Endpoint.objects\n",
    "        .filter(assessment__vocabulary=1, system_term_id__isnull=True)\n",
    "        .values(\"system\")\n",
    "        .annotate(count=Count('id', distinct=True))\n",
    "        .order_by('-count')\n",
    "        .filter(count__gt=2)\n",
    ")\n",
    "qs2 = (\n",
    "    Endpoint.objects\n",
    "        .filter(assessment__vocabulary=1, organ_term_id__isnull=True)\n",
    "        .values(\"organ\")\n",
    "        .annotate(count=Count('id', distinct=True))\n",
    "        .order_by('-count')\n",
    "        .filter(count__gt=2)\n",
    ")\n",
    "qs3 = (\n",
    "    Endpoint.objects\n",
    "        .filter(assessment__vocabulary=1, effect_term_id__isnull=True)\n",
    "        .values(\"effect\")\n",
    "        .annotate(count=Count('id', distinct=True))\n",
    "        .order_by('-count')\n",
    "        .filter(count__gt=2)\n",
    ")\n",
    "qs4 = (\n",
    "    Endpoint.objects\n",
    "        .filter(assessment__vocabulary=1, effect_subtype_term_id__isnull=True)\n",
    "        .values(\"effect_subtype\")\n",
    "        .annotate(count=Count('id', distinct=True))\n",
    "        .order_by('-count')\n",
    "        .filter(count__gt=2)\n",
    ")\n",
    "qs5 = (\n",
    "    Endpoint.objects\n",
    "        .filter(assessment__vocabulary=1, name_term_id__isnull=True)\n",
    "        .values(\"name\")\n",
    "        .annotate(count=Count('id', distinct=True))\n",
    "        .order_by('-count')\n",
    "        .filter(count__gt=2)\n",
    ")\n",
    "\n",
    "df2 = pd.concat([\n",
    "       pd.DataFrame(qs1).assign(type=\"system\").rename(columns={\"system\":\"term\"}),\n",
    "       pd.DataFrame(qs2).assign(type=\"organ\").rename(columns={\"organ\":\"term\"}),\n",
    "       pd.DataFrame(qs3).assign(type=\"effect\").rename(columns={\"effect\":\"term\"}),\n",
    "       pd.DataFrame(qs4).assign(type=\"effect_subtype\").rename(columns={\"effect_subtype\":\"term\"}),\n",
    "       pd.DataFrame(qs5).assign(type=\"name\").rename(columns={\"name\":\"term\"}),\n",
    "]).sort_values('count', ascending=False)[['type', 'term', 'count']]\n",
    "print(df2.shape[0])\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e4d20-e7fb-44e2-904d-5be662361d91",
   "metadata": {},
   "source": [
    "## Write exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad57627c-d9d1-43f4-b92f-e2f87ac085bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(f'data/hawc-candidate-terms-endpoints.csv', index=False)\n",
    "df2.to_csv(f'data/hawc-candidate-terms-ranked.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8701341-e1c4-47b9-9c67-11249bd8e255",
   "metadata": {},
   "source": [
    "## Identify EHV candidate terms for manual curation or synonyms to incorporate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63a02c-ae1e-4ff4-b150-196e397f8d33",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c41109fb-27be-4ddc-a7bb-fc40f0e2c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hawc = pd.read_csv(r'data/hawc-candidate-terms-endpoints.csv')\n",
    "ehv  = pd.read_excel(r'data/ehv.xlsx')\n",
    "OUTPUT_FOLDER = r'data/Output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d51a9-41f2-4c7f-9691-2c0d60aa02a2",
   "metadata": {},
   "source": [
    "### String Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03540c03-3c28-4b76-a7dc-cfac0d9b6eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeCodes(text):  # removes numeric codes at the end of a string (that start with XXX or are numbers)\n",
    "    text = re.sub(r'XXX\\d+$', '', str(text)).strip()\n",
    "    text = re.sub(r'\\d+$', '', str(text)).strip()\n",
    "    return(text)\n",
    "\n",
    "def remove_characters(text, character_list = [\"?\",\"!\",\".\",\"/\"] ): # replaces punctuation with space + punctuation + space \n",
    "    text = text.translate(''.join(character_list))\n",
    "    return(text)\n",
    "\n",
    "def replace_dashes(text): # replaces dashes with spaces\n",
    "    text = text.replace('-',' ')\n",
    "    return(text)\n",
    "\n",
    "def replace_surpluswhitespace(text): # replace multiple whitespaces with single space and gets rid of trailing and leading spaces.\n",
    "    text =' '.join(text.split())\n",
    "    return(text)\n",
    "\n",
    "def lowerText(text):\n",
    "    text = text.lower()\n",
    "    return(text)\n",
    "\n",
    "def removeParentheses(text):\n",
    "    text = re.sub(r\"[\\(\\[].*?[\\)\\]]\", \"\", str(text))\n",
    "    return(text)\n",
    "\n",
    "def lemmaString(text):\n",
    "    doc = nlp(text)\n",
    "    text = [token.lemma_ for token in doc]\n",
    "    text = ' '.join(text)\n",
    "    return(text)\n",
    "\n",
    "def preProcessing(text):\n",
    "    text = removeParentheses(text)\n",
    "    text = removeCodes(text)\n",
    "    text = remove_characters(text)\n",
    "    text = replace_dashes(text)\n",
    "    text = replace_surpluswhitespace(text)\n",
    "    text = lowerText(text)\n",
    "    text = lemmaString(text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2cc130d-0d83-45f8-9780-6e2b19e5fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hawc = hawc.iloc[:1000].copy() # make subset of dataset for quicker development iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba88afa4-d6f5-436d-97a6-eb557f540c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.54 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "hawc[\"1_cleaned\"] = hawc['name'].apply(preProcessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b2ad491-2ce0-4a9b-81a8-2dd4d5a452f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.1 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "ehv['1_cleaned']  = ehv['name'].apply(preProcessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "735f484b-18ca-4ea5-a05f-cc4d3e962067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hawc_ehv_merged = pd.merge(hawc, ehv, how='left', on=\"1_cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd3ba65-08ef-4194-af13-ba45f5209ee8",
   "metadata": {},
   "source": [
    "#### Match a candidate term from HAWC to an EHV term using Levenshtein Distance\n",
    "##### This method also compares whether effect and effect_subtype match. Some entries in HAWC invert effect and effect_subtype. This method will resolve to \"True\" regardless of an inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3afed875-a243-439e-a051-a41e6089b8b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 99.99 # can add a threshold cutoff here and limit response output if desired\n",
    "\n",
    "response = []\n",
    "for i,row in hawc.iterrows():\n",
    "    candidate_term = row[\"1_cleaned\"]\n",
    "    resp_match =  process.extractOne(candidate_term,ehv[\"1_cleaned\"] , scorer=fuzz.token_sort_ratio)\n",
    "    resp = row.to_dict()\n",
    "    resp[\"match_score\"] = resp_match[1] # add the Levenshtein Distance\n",
    "    resp[\"join_on\"] = resp_match[2]\n",
    "    resp[\"effects_match\"] = set([resp[\"effect\"],resp[\"effect_subtype\"]]).issubset( \n",
    "        set([ehv.iloc[resp_match[2]][\"effect\"],ehv.iloc[resp_match[2]][\"effect_subtype\"]])) # determine whether the effect and effect_types match\n",
    "    response.append(resp)\n",
    "\n",
    "results = pd.DataFrame(response)\n",
    "results_merged = results.merge(ehv, right_index=True, left_on=\"join_on\",suffixes=[\"_hawc\",\"_ehv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82313cf3-c25d-4bdb-b776-4c294246455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_merged.to_excel(\"data/FuzzyMatching_ExcludingParentheses_Lemma_Results.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c049b68e-b32a-4dd1-819c-881b3b2d1653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1515aa1a-a80d-4932-93d9-d1d42f3f437f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
